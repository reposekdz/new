
const { GoogleGenAI } = require("@google/genai");
const { getSystemInstruction, getExecutionSystemInstruction } = require('../utils/prompts');

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

const MAX_RETRIES = 2;

// --- HELPER: COMPLEXITY ANALYSIS ---
const analyzeComplexity = (prompt) => {
    const complexKeywords = [
        'architecture', 'backend', 'database', 'auth', 'realtime', 'socket', 
        'dashboard', 'cms', 'saas', 'enterprise', 'refactor', 'optimize',
        'video editor', 'game engine', '3d', 'webgl', 'webgpu', 'three.js',
        'rust', 'c++', 'cpp', 'assembly', 'cuda', 'ffmpeg', 'ai model',
        'security', 'encryption', 'blockchain'
    ];
    const score = complexKeywords.reduce((acc, kw) => prompt.toLowerCase().includes(kw) ? acc + 1 : acc, 0);
    return score > 0;
};

// --- HELPER: AUTO-HEALING JSON PARSER ---
const parseHealedJson = (text) => {
    try {
        // Attempt direct parse
        return JSON.parse(text);
    } catch (e) {
        // 1. Remove Markdown Code Blocks (```json ... ```)
        let cleaned = text.replace(/```json/g, '').replace(/```/g, '').trim();
        try { return JSON.parse(cleaned); } catch (e2) { /* continue */ }

        // 2. Extract Array from Text using Regex
        // Looks for the first [ and the last ] to capture the JSON array
        const match = cleaned.match(/\[\s*\{.*\}\s*\]/s);
        if (match) {
            try { return JSON.parse(match[0]); } catch (e3) { /* continue */ }
        }
        
        // 3. Attempt to fix common trailing comma issues (simple case)
        cleaned = cleaned.replace(/,(\s*[\]}])/g, '$1');
        try { return JSON.parse(cleaned); } catch (e4) { /* continue */ }

        console.error("Failed JSON Text:", text);
        throw new Error("Failed to parse JSON response from AI after multiple attempts.");
    }
};

// --- HELPER: ADVANCED SCAFFOLDING ---
const setupProject = (files, prompt) => {
  const newFiles = [...files];
  const filePaths = new Set(newFiles.map(f => f.path));

  // 1. Detect Tech Stack
  const promptLower = prompt.toLowerCase();
  const isPython = newFiles.some(f => f.path.endsWith('.py')) || promptLower.includes('python');
  const isRust = newFiles.some(f => f.path.endsWith('.rs')) || promptLower.includes('rust');
  const isCpp = newFiles.some(f => f.path.endsWith('.cpp') || f.path.endsWith('.h')) || promptLower.includes('c++');
  const isNode = newFiles.some(f => f.path.match(/\.(js|ts|jsx|tsx)$/)) || (!isPython && !isRust && !isCpp);
  const isTypescript = newFiles.some(f => f.path.match(/\.(ts|tsx)$/)) || promptLower.includes('typescript');

  // 2. Generate .gitignore if missing
  if (!filePaths.has('.gitignore')) {
    let content = "node_modules/\n.env\n.DS_Store\ndist/\nbuild/\n.vscode/\ncoverage/";
    if (isPython) content += "\n__pycache__/\n*.pyc\nvenv/\n.pytest_cache/";
    if (isRust) content += "\ntarget/\nCargo.lock";
    if (isCpp) content += "\nbuild/\n*.o\n*.exe\n*.out";
    newFiles.push({ path: '.gitignore', content });
  }

  // 3. Generate package.json (Node/React)
  if (isNode && !filePaths.has('package.json')) {
    const pkg = {
      name: "omnigen-project",
      version: "1.0.0",
      description: "Generated by OmniGen AI",
      main: isTypescript ? "src/main.tsx" : "src/index.jsx",
      type: "module",
      scripts: {
        "start": "vite",
        "build": "vite build",
        "preview": "vite preview",
        "lint": "eslint ."
      },
      dependencies: {
        "react": "^18.2.0",
        "react-dom": "^18.2.0",
        "lucide-react": "^0.344.0",
        "clsx": "^2.1.0",
        "tailwind-merge": "^2.2.1"
      },
      devDependencies: {
        "@vitejs/plugin-react": "^4.2.1",
        "autoprefixer": "^10.4.18",
        "postcss": "^8.4.35",
        "tailwindcss": "^3.4.1",
        "vite": "^5.1.4"
      }
    };
    
    if (isTypescript) {
        pkg.devDependencies["typescript"] = "^5.2.2";
        pkg.devDependencies["@types/react"] = "^18.2.66";
        pkg.devDependencies["@types/react-dom"] = "^18.2.22";
    }
    
    newFiles.push({ path: 'package.json', content: JSON.stringify(pkg, null, 2) });
  }

  // 4. Inject tsconfig.json
  if (isTypescript && !filePaths.has('tsconfig.json')) {
      newFiles.push({
          path: 'tsconfig.json',
          content: JSON.stringify({
            compilerOptions: {
                target: "ES2020",
                useDefineForClassFields: true,
                lib: ["ES2020", "DOM", "DOM.Iterable"],
                module: "ESNext",
                skipLibCheck: true,
                moduleResolution: "bundler",
                allowImportingTsExtensions: true,
                resolveJsonModule: true,
                isolatedModules: true,
                noEmit: true,
                jsx: "react-jsx",
                strict: true,
                unusedLocals: false,
                unusedParameters: false,
                noFallthroughCasesInSwitch: true
            },
            include: ["src"],
            references: [{ path: "./tsconfig.node.json" }]
          }, null, 2)
      });
      
      // Add tsconfig.node.json usually needed for Vite
      if (!filePaths.has('tsconfig.node.json')) {
          newFiles.push({
              path: 'tsconfig.node.json',
              content: JSON.stringify({
                compilerOptions: {
                    composite: true,
                    skipLibCheck: true,
                    module: "ESNext",
                    moduleResolution: "bundler",
                    allowSyntheticDefaultImports: true
                },
                include: ["vite.config.ts"]
              }, null, 2)
          });
      }
  }

  return newFiles;
};

// --- MAIN FUNCTION: GENERATE APP ---
const generateApp = async ({ userPrompt, model, attachments = [], currentFiles = [], history = [] }) => {
  const isModification = currentFiles.length > 0 || history.length > 0;
  const systemInstruction = getSystemInstruction(isModification);
  
  // Construct the full context message
  let promptContext = `User Request: ${userPrompt}\n\n`;
  
  if (currentFiles.length > 0) {
      const fileSummary = currentFiles.map(f => `${f.path}`).join(', ');
      promptContext += `Current Project Structure: ${fileSummary}\n`;
      
      // Optimization: Only send full content of relevant files if list is huge, 
      // but for this demo we send all to ensure context.
      promptContext += `Current File Contents:\n${JSON.stringify(currentFiles)}\n\n`;
  }
  
  if (history.length > 0) {
      promptContext += `Conversation History:\n${history.map(h => `${h.role}: ${h.text}`).join('\n')}\n\n`;
  }

  // Config
  const isComplex = analyzeComplexity(userPrompt);
  // Force Pro model for complex tasks if not explicitly set (or if user is on default)
  const effectiveModel = (isComplex && model === 'gemini-2.5-flash') ? 'gemini-3-pro-preview' : model;
  const shouldUseThinking = effectiveModel.includes('pro') || isComplex;

  // Prepare Parts
  const parts = [{ text: promptContext }];
  
  // Add attachments (Images/Text)
  for (const att of attachments) {
      if (att.isImage) {
          // Remove data:image/png;base64, prefix if present
          const base64Data = att.content.split(',')[1] || att.content;
          parts.push({
              inlineData: {
                  mimeType: att.type,
                  data: base64Data
              }
          });
      } else {
          parts.push({ text: `Attachment (${att.name}):\n${att.content}` });
      }
  }

  // Retry Loop
  for (let attempt = 0; attempt <= MAX_RETRIES; attempt++) {
      try {
        // Note: We create a new model instance per request if configs change dynamically, 
        // but generally one instance is fine if configs are passed in generateContent.
        
        const response = await ai.models.generateContent({
            model: effectiveModel,
            contents: { parts },
            config: {
                systemInstruction,
                responseMimeType: 'application/json',
                // Thinking Config (Only for 2.5 series currently, but safe to omit if not needed)
                // thinkingConfig: shouldUseThinking ? { thinkingBudget: 4096 } : undefined,
                temperature: isModification ? 0.2 : 0.7, // Lower temp for code mods to be precise
            }
        });

        const text = response.text;
        if (!text) throw new Error("Empty response from AI");

        // Parse and Heal
        let files = parseHealedJson(text);

        // Validation: Ensure it's an array
        if (!Array.isArray(files)) {
             // Sometimes models return { "files": [...] }
             if (files.files && Array.isArray(files.files)) {
                 files = files.files;
             } else {
                 throw new Error("AI response was not a JSON array of files");
             }
        }

        // Post-Processing: Merge with existing files if modification
        if (isModification) {
            // Update existing files or add new ones
            const updatedFilesMap = new Map(currentFiles.map(f => [f.path, f]));
            files.forEach(f => {
                updatedFilesMap.set(f.path, f);
            });
            files = Array.from(updatedFilesMap.values());
        }

        // Post-Processing: Scaffolding
        files = setupProject(files, userPrompt);

        return files;

      } catch (err) {
          console.error(`Attempt ${attempt + 1} failed:`, err.message);
          if (attempt === MAX_RETRIES) throw err;
          // Exponential backoff
          await new Promise(r => setTimeout(r, 1000 * Math.pow(2, attempt)));
      }
  }
};

// --- SIMULATION EXECUTION ---
const runSimulation = async (files, command) => {
  try {
      // 1. Contextualize the execution environment
      const fileContext = files.map(f => `[FILE: ${f.path}]\n${f.content}`).join('\n\n');
      
      const response = await ai.models.generateContent({
          model: 'gemini-2.5-flash', // Use Flash for fast terminal responses
          contents: `CONTEXT:\n${fileContext}\n\nCOMMAND: ${command}`,
          config: {
              systemInstruction: getExecutionSystemInstruction(),
              temperature: 0.1
          }
      });

      return response.text;
  } catch (error) {
      return `Error executing command: ${error.message}`;
  }
};

module.exports = { generateApp, runSimulation };
